{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de8a54f1-a15e-44ee-acb3-11e9e1363da2",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5f90ac4-fd10-4f66-aa3c-82097fbb72d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9325f7-4bca-44f8-b947-e02009bf2510",
   "metadata": {},
   "source": [
    "### Define train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b826c42-4ed3-46be-ad67-98cce89749bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1.5, 0.8, 0.4],\n",
    "                   [2.0, 1.0, 2.3],\n",
    "                   [2.2, 1.2, 8.4],\n",
    "                   [2.4, 1.5, 3.1],\n",
    "                   [3.0, 2.0, 6.8],\n",
    "                   [3.5, 2.5, 5.3],\n",
    "                   [4.0, 3.0, 1.7],\n",
    "                   [4.5, 3.5, 12.3],\n",
    "                   [5.0, 4.0, 4.2],\n",
    "                   [5.5, 4.5, 15.2]])\n",
    "Y_train = np.array([2.3, 1.2, 2.54, 4.6, 1.2, 1.9, 2.7, 1.2, 2.5, 3.8])\n",
    "\n",
    "X_unseen= np.array([[3.0, 4.2, 7.9], [7.2, 8.6, 10.5], [10.2, 12.3, 6.9]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a70bad-5ffe-42eb-adf3-30d3c6261016",
   "metadata": {},
   "source": [
    "### Define a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65cc8248-62a5-4325-8593-7677c5a2d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, left=None, right=None, feature_index=None, threshold=None, value=None):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d77c3b89-a851-4508-a49d-09d100da6dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTree:\n",
    "    def __init__(self, max_depth):\n",
    "        self.max_depth = max_depth\n",
    "        self.model = None\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        self.model = self._grow(X, Y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predicting every x examples' feature values with the calculated decision tree\n",
    "        return np.array([self._predict(x, self.model) for x in X])\n",
    "\n",
    "    def _grow(self, X, Y, depth=0):\n",
    "        num_samples, num_features = X.shape\n",
    "        num_classes = len(np.unique(Y))\n",
    "        \n",
    "        best_mape = math.inf\n",
    "        best_index = None\n",
    "        best_threshold = None\n",
    "        best_sets = None\n",
    "\n",
    "        # Base case, if there's only 1 class or has reach max depth\n",
    "        if num_classes == 1 or depth == self.max_depth:\n",
    "            return Node(value=np.mean(Y))\n",
    "\n",
    "        # Loop through all the features\n",
    "        for feature_index in range(num_features):\n",
    "            # Find thresholds\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "\n",
    "            # For each threshold, split the chosen feature set into half base on the value of chosen threshold.\n",
    "            # Our goal is to find the best threshold to divide classes\n",
    "            for threshold in thresholds:\n",
    "                left_indices = np.where(X[:, feature_index] <= threshold)[0]\n",
    "                right_indices = np.where(X[:, feature_index] > threshold)[0]\n",
    "\n",
    "                # If one or the other side is empty, we don't consider it\n",
    "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "                    continue\n",
    "\n",
    "                # Perform MAPE on both left and right\n",
    "                Y_left = Y[left_indices]\n",
    "                Y_right = Y[right_indices]\n",
    "\n",
    "                Y_pred_left = np.mean(Y_left)\n",
    "                Y_pred_right = np.mean(Y_right)\n",
    "                \n",
    "                mape_left = self._mean_absolute_percentage_error(Y_left, Y_pred_left)\n",
    "                mape_right = self._mean_absolute_percentage_error(Y_right, Y_pred_right)\n",
    "\n",
    "                mape = (np.sum(left_indices) * mape_left + np.sum(right_indices) * mape_right) / num_samples\n",
    "\n",
    "                # If that mape is better than the current best, we store it to use later\n",
    "                if mape < best_mape:\n",
    "                    best_mape = mape\n",
    "                    best_index = feature_index\n",
    "                    best_threshold = threshold\n",
    "                    best_sets = (left_indices, right_indices)\n",
    "\n",
    "        # If for any reason mape score hasn't been calculated\n",
    "        if best_mape == math.inf:\n",
    "            return Node(value=np.mean(Y))\n",
    "\n",
    "        # Continue to grow recursively of both left and right side and append it to the current node\n",
    "        # using the best sets that we have found above\n",
    "        left = self._grow(X[best_sets[0]], Y[best_sets[0]], depth + 1)\n",
    "        right = self._grow(X[best_sets[1]], Y[best_sets[1]], depth + 1)\n",
    "        \n",
    "        return Node(feature_index=best_index, threshold=best_threshold, left=left, right=right)\n",
    "\n",
    "    def _mean_absolute_percentage_error(self, Y_actual, Y_pred):\n",
    "        return np.mean(np.abs((Y_actual - Y_pred) / Y_actual)) * 100\n",
    "        \n",
    "    def _predict(self, x, node):\n",
    "        # Return prediction value if it's available, aka. bottom of the tree\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "\n",
    "        # Else descend lower into the tree and return the final prediction all the way up\n",
    "        if x[node.feature_index] <= node.threshold:\n",
    "            return self._predict(x, node.left)\n",
    "        else:\n",
    "            return self._predict(x, node.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795a8bf5-3719-448b-9f34-39366b9494ee",
   "metadata": {},
   "source": [
    "#### Testing out decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43786f01-026e-45a8-91dc-5245f0ae14ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model prediction: [1.2 3.8 3.8]\n",
      "Sklearn model prediction: [1.2 3.8 3.8]\n"
     ]
    }
   ],
   "source": [
    "dtree = DTree(5)\n",
    "dtree.train(X_train, Y_train)\n",
    "print(\"Our model prediction: \" + str(dtree.predict(X_unseen)))\n",
    "\n",
    "# Comparing to Sklearn\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Since our implementation doesn't have any randomness involved, we need to set a fixed random seed\n",
    "dtree = DecisionTreeRegressor(max_depth=5, random_state=1)\n",
    "dtree.fit(X_train, Y_train)\n",
    "print(\"Sklearn model prediction: \" + str(dtree.predict(X_unseen)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc5f54-4276-45c9-b763-e35c13bf2b4f",
   "metadata": {},
   "source": [
    "### Define a random forest using the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a500c79-74a5-45f5-916b-9fe570161df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, num_tree, max_tree_depth, max_feature, seed):\n",
    "        self.num_tree = num_tree\n",
    "        self.trees = []\n",
    "        self.max_tree_depth = max_tree_depth\n",
    "        self.max_feature = max_feature\n",
    "        self.seed = seed\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        np.random.seed(self.seed)\n",
    "        \n",
    "        for _ in range(self.num_tree):\n",
    "            # Choosing random examples to train with, or bootstrapping with replacement\n",
    "            sample_indices = np.random.choice(X.shape[0], size=X.shape[0], replace=True)\n",
    "\n",
    "            # Choosing random features to train with without replacement\n",
    "            feature_indices = np.random.choice(X.shape[1], size=self.max_feature, replace=False)\n",
    "\n",
    "            # Compiling into a training data format\n",
    "            X_training = X[sample_indices][:, feature_indices]\n",
    "            Y_training = Y[sample_indices]\n",
    "\n",
    "            dtree = DTree(self.max_tree_depth)\n",
    "            dtree.train(X_training, Y_training)\n",
    "            self.trees.append(dtree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "\n",
    "        # Calculate result for individual trees\n",
    "        for tree in self.trees:\n",
    "            predictions.append(tree.predict(X))\n",
    "\n",
    "        # Averaging from all the predictions each trees made\n",
    "        return np.mean(predictions, axis=0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051674cd-ba6c-4c32-b299-07349e01dc76",
   "metadata": {},
   "source": [
    "#### Testing out random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ba39f26-e9c5-42d2-beca-769d3d222449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model prediction: [2.36033333 3.0078     2.9712    ]\n",
      "Sklearn model prediction: [2.0686 2.9921 2.9761]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForest(num_tree=100, max_tree_depth=5, max_feature=2, seed=1)\n",
    "rf.train(X_train, Y_train)\n",
    "print(\"Our model prediction: \" + str(rf.predict(X_unseen)))\n",
    "\n",
    "# Comparing to Sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(max_depth=5, random_state=1, criterion='absolute_error', max_features=2, n_estimators=100)\n",
    "rf.fit(X_train, Y_train)\n",
    "print(\"Sklearn model prediction: \" + str(rf.predict(X_unseen)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
